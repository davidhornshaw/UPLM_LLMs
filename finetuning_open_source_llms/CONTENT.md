The Uplimit course "Finetuning Open Source LLMs" (14.10. -  03.11.2024) teaches SOTA techniques for prompt data preprocessing and management, as well as LLM fintetuning and inference. It consists of the following three projects:

1. Exploring LLM Dataset Creation and Evaluation:
    Creating a workspace on a public Argilla instance,
    Creating a distilab pipeline to generate prompt responses on a preprocessed open source dataset and push to a public Argilla instance,
    Evaluate an open source LLM using the Eleuther evaluation Harness and push results to a model repository on Huggingface. [Not included in this repository.]
    
2. Productizing Open Source Large Language Models: